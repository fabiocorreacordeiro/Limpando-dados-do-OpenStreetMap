{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** UDACITY **\n",
    "\n",
    "** Nanodegree Analista de Dados **\n",
    "\n",
    "### Projeto: Limpando dados do OpenStreetMap\n",
    "\n",
    "# Baía de Guanabara, Rio de Janeiro - Brasil\n",
    "\n",
    "**por Fábio Corrêa Cordeiro**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esse notebook contém os códigos necessários para a realizaçõ do projeto \"P3: Limpando dados do OpenStreetMap\" do Nanodegree Analista de Dados. Serão utilizados os mesmo código utilizados na lição 18 \"Estudo de Caso: Dados do Street Map\" com as devidas alterações necessárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import xml.etree.cElementTree as ET\n",
    "import pprint\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import codecs\n",
    "import json\n",
    "from pymongo import MongoClient\n",
    "\n",
    "\"\"\" Choosing dataset \"\"\"\n",
    "# test file\n",
    "#filename = 'Jardim_Guanabara_OSM'\n",
    "\n",
    "# test file2\n",
    "#filename = 'Niteroi OSM.osm'\n",
    "\n",
    "# original file\n",
    "filename = 'Guanabara_Bay_OSM'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 Quiz: Tratamento iterativo\n",
    "\n",
    "*Your task is to use the iterative parsing to process the map file and find out not only what tags are there, but also how many, to get the feeling on how much of which data you can expect to have in the map. Fill out the count_tags function. It should return a dictionary with the tag name as the key and number of times this tag can be encountered in \n",
    "the map as value.*\n",
    "\n",
    "*Note that your code will be tested with a different data file than the 'example.osm'*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'node': 722986, 'member': 24789, 'nd': 986138, 'tag': 359012, 'note': 1, 'meta': 1, 'osm': 1, 'way': 100569, 'relation': 2671}\n"
     ]
    }
   ],
   "source": [
    "def count_tags(filename):\n",
    "    \"\"\" For a given file this function returns a dictionary of types of tags and number of elements. \"\"\"\n",
    "    tree = ET.parse(filename)\n",
    "    root = tree.getroot()\n",
    "    data = {}\n",
    "    for leaf in root.iter():\n",
    "        if leaf.tag not in data:\n",
    "            data[leaf.tag]=1\n",
    "        else:\n",
    "            data[leaf.tag]+=1\n",
    "    return data\n",
    "\n",
    "tags = count_tags(filename)\n",
    "print tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 Quiz: Modelo de Dados\n",
    "\n",
    "*Your task is to explore the data a bit more. Before you process the data and add it into your database, you should check the\n",
    "\"k\" value for each \"<tag>\" and see if there are any potential problems.*\n",
    "\n",
    "*We have provided you with 3 regular expressions to check for certain patternsin the tags. As we saw in the quiz earlier, we would like to change the datamodel and expand the \"addr:street\" type of keys to a dictionary like this:*\n",
    "\n",
    "*{\"address\": {\"street\": \"Some value\"}}*\n",
    "\n",
    "*So, we have to see if we have such tags, and if we have any tags withproblematic characters.*\n",
    "\n",
    "*Please complete the function 'key_type', such that we have a count of each of four tag categories in a dictionary:*\n",
    "  * *\"lower\", for tags that contain only lowercase letters and are valid,*\n",
    "  * *\"lower_colon\", for otherwise valid tags with a colon in their names,*\n",
    "  * *\"problemchars\", for tags with problematic characters, and*\n",
    "  * *\"other\", for other tags that do not fall into the other three categories.*\n",
    "*See the 'process_map' and 'test' functions for examples of the expected format.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'problemchars': 1, 'lower': 323963, 'other': 11403, 'lower_colon': 23645}\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Regular expression for identification of lower caps, colons and other problem characters. \"\"\"\n",
    "lower = re.compile(r'^([a-z]|_)*$')\n",
    "lower_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*$')\n",
    "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "\n",
    "def key_type(element, keys):\n",
    "    \"\"\" \n",
    "    This function identify if a element has lower caps, colons, problem characters\n",
    "    and other characters, and update the key dictionary.\n",
    "    \"\"\"\n",
    "    if element.tag == \"tag\":\n",
    "        if lower.search(element.attrib['k']) != None:\n",
    "            keys[\"lower\"] += 1\n",
    "        else:\n",
    "            if lower_colon.search(element.attrib['k']) != None:\n",
    "                keys[\"lower_colon\"] += 1\n",
    "            else:    \n",
    "                if problemchars.search(element.attrib['k']) != None:\n",
    "                    keys[\"problemchars\"] += 1\n",
    "                else:\n",
    "                    keys[\"other\"] += 1\n",
    "    return keys\n",
    "\n",
    "def process_map(filename):\n",
    "    \"\"\"\n",
    "    For a file, return a dictionary of how many elements has lower caps, colons, problem characters\n",
    "    and other characters\n",
    "    \"\"\"\n",
    "    keys = {\"lower\": 0, \"lower_colon\": 0, \"problemchars\": 0, \"other\": 0}\n",
    "    for _, element in ET.iterparse(filename):\n",
    "        keys = key_type(element, keys)\n",
    "    return keys\n",
    "\n",
    "keys = process_map(filename)\n",
    "print keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8 Quiz: Investigando usuários\n",
    "\n",
    "*Your task is to explore the data a bit more.*\n",
    "*The first task is a fun one - find out how many unique users*\n",
    "*have contributed to the map in this particular area!*\n",
    "\n",
    "*The function process_map should return a set of unique user IDs (\"uid\")*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N° unique user IDs:  1112\n"
     ]
    }
   ],
   "source": [
    "def get_user(element):\n",
    "    \"\"\" For an element gets the attribute 'user'. \"\"\"\n",
    "    try:\n",
    "        return element.attrib['user']\n",
    "    except:\n",
    "        return\n",
    "\n",
    "\n",
    "def process_map(filename):\n",
    "    \"\"\" For a file, parses all element and return a set of list of users. \"\"\"\n",
    "    users = set()\n",
    "    for _, element in ET.iterparse(filename):\n",
    "        if get_user(element) != None:\n",
    "            users.add(get_user(element))\n",
    "    return users\n",
    "\n",
    "users = process_map(filename)\n",
    "print 'N° unique user IDs: ', len(users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11 Quiz: Melhorando o nome das ruas\n",
    "\n",
    "*Your task in this exercise has two steps:*\n",
    "\n",
    "- *audit the OSMFILE and change the variable 'mapping' to reflect the changes needed to fix* \n",
    "    *the unexpected street types to the appropriate ones in the expected list.*\n",
    "    *You have to add mappings only for the actual problems you find in this OSMFILE,*\n",
    "    *not a generalized solution, since that may and will depend on the particular area you are auditing.*\n",
    "- *write the update_name function, to actually fix the street name.*\n",
    "    *The function takes a string with street name as an argument and should return the fixed name*\n",
    "    *We have provided a simple test so that you see what exactly is expected*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199 => 199\n",
      "Voluntarios da Patria => Voluntarios da Patria\n",
      "Pca Pio X => Praça Pio X\n",
      "Marquês de Paraná => Marquês de Paraná\n",
      "Dias da Cruz => Dias da Cruz\n",
      "Dias Pereira => Dias Pereira\n",
      "Praca Senador Salgado Filho => Praça Senador Salgado Filho\n",
      "Praca Marechal Floriano => Praça Marechal Floriano\n",
      "Auto Estrada Lagoa-Barra => Auto Estrada Lagoa-Barra\n",
      "Rue Sao Clemente => Rua Sao Clemente\n",
      "Rue Almirante Alexandrino => Rua Almirante Alexandrino\n",
      "Aires Itabaiana => Aires Itabaiana\n",
      "Assis Bueno => Assis Bueno\n",
      "PLAZA DE MUHAMMAD ALI, GAMBOA => Praça DE MUHAMMAD ALI, GAMBOA\n",
      "Professor Fioravanti Di Piero => Professor Fioravanti Di Piero\n",
      "rua das laranjeiras => Rua das laranjeiras\n",
      "R. Profa. Paula Aquiles => Rua Profa. Paula Aquiles\n",
      "R. Bastista de Oliveira => Rua Bastista de Oliveira\n",
      "R. Miguel Gustavo => Rua Miguel Gustavo\n",
      "R. José Bento Viêira Ferreira => Rua José Bento Viêira Ferreira\n",
      "Fernandes Guimarães => Fernandes Guimarães\n",
      "São Manoel => São Manoel\n",
      "Goethe => Goethe\n",
      "Pça. da Bandeira => Pça. da Bandeira\n",
      "Pça Carlos de Laet => Pça Carlos de Laet\n",
      "Bernadino dos Santos => Bernadino dos Santos\n",
      "Rod. Washington Luiz => Rodovia Washington Luiz\n",
      "Rod. Washigton Luiz => Rodovia Washigton Luiz\n",
      "General Polidoro => General Polidoro\n",
      "Trav Mario dos Santos => Travessa Mario dos Santos\n",
      "Heráclito Graça => Heráclito Graça\n",
      "Av das Americas 15500 => Avenida das Americas 15500\n",
      "Av Presidente Wilson => Avenida Presidente Wilson\n",
      "Av. Atlântica => Avenida Atlântica\n",
      "Av Padre Anchieta => Avenida Padre Anchieta\n",
      "Av. Afranio de Melo Franco => Avenida Afranio de Melo Franco\n",
      "Av Rotary => Avenida Rotary\n",
      "Av. Milton Tavares de Souza => Avenida Milton Tavares de Souza\n",
      "Av. N. S. de Copacabana => Avenida N. S. de Copacabana\n",
      "Av. Brasil => Avenida Brasil\n"
     ]
    }
   ],
   "source": [
    "\"\"\" This regular expression has been changed to capture the first word and not the last one. \"\"\"\n",
    "street_type_re = re.compile(r'^\\S+\\b', re.IGNORECASE)\n",
    "\n",
    "\n",
    "\"\"\" Updated list with the \"street_types\" found on the Guanabara Bay map. \"\"\"\n",
    "expected = [\"Rua\", \"Avenida\", \"Quadra\", \"Via\", \"Estrada\", \"Caminho\", \"Estacionamento\", \"Parque\", \"Praia\",\n",
    "           \"Alameda\",\"Beco\",\"Campo\", \"Ladeira\", \"Largo\", \"Mirante\", \"Rodovia\", \"Travessa\", \"Praça\", 'Boulevard',\n",
    "           \"Calçadão\" ,\"Condomínio\"]\n",
    "\n",
    "\"\"\" Mapping updated with the errors and abbreviations found on the Guanabara Bay map. \"\"\"\n",
    "mapping = { \n",
    "            'Av ': \"Avenida \",\n",
    "            'Av. ': \"Avenida \",\n",
    "            'PLAZA ': \"Praça \",\n",
    "            'Pca ': \"Praça \",\n",
    "            'Praca ': \"Praça \",\n",
    "            'R. ': \"Rua \",\n",
    "            'R ': \"Rua \",\n",
    "            'Rue ': \"Rua \",\n",
    "            'rua ': \"Rua \",\n",
    "            'Rod ': \"Rodovia \",\n",
    "            'Rod. ': \"Rodovia \",\n",
    "            'Trav ': \"Travessa \"\n",
    "            }\n",
    "          \n",
    "\n",
    "\"\"\"\n",
    "It was necessary to add \".encode ('utf8')\" in the comparison of strings\n",
    "of the function \"audit_street_type\" due to the special characters\n",
    "of the Portuguese language.\n",
    "\"\"\"\n",
    "def audit_street_type(street_types, street_name):\n",
    "    \"\"\" For a given dictionary of street_types and a street name returns the dictionary updated. \"\"\"\n",
    "    m = street_type_re.search(street_name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        if street_type.encode('utf8') not in expected:\n",
    "            street_types[street_type].add(street_name)\n",
    "            return street_types\n",
    "\n",
    "\n",
    "def is_street_name(elem):\n",
    "    \"\"\" Returns True if attrib['k'] of an element is \"addr:street\". \"\"\"\n",
    "    return (elem.attrib['k'] == \"addr:street\")\n",
    "\n",
    "\n",
    "def audit(osmfile):\n",
    "    \"\"\" For a given file returns a dictionary with the \"street_types\". \"\"\"\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    street_types = defaultdict(set)\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_street_name(tag):\n",
    "                    audit_street_type(street_types, tag.attrib['v'])\n",
    "                    tag.attrib['v'] = update_name(tag.attrib['v'], mapping)\n",
    "    osm_file.close()\n",
    "    return street_types\n",
    "\n",
    "\n",
    "def update_name(name, mapping):\n",
    "    \"\"\" Update the street name using the mapping dictionary. \"\"\"\n",
    "    for target_name in mapping:\n",
    "        if name.find(target_name) != -1:\n",
    "            a = name[:name.find(target_name)]\n",
    "            b = mapping[target_name]\n",
    "            c = name[name.find(target_name)+len(target_name):]\n",
    "            name = a + b + c\n",
    "    return name\n",
    "\n",
    "st_types = audit(filename)\n",
    "\n",
    "for st_type, ways in st_types.iteritems():\n",
    "    for name in ways:\n",
    "        better_name = update_name(name, mapping)\n",
    "        print name, \"=>\", better_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Além de verificar os nomes das ruas, como solicitado no exercício, resolvermos auditar o nome das cidades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set(['Maric\\xc3\\xa1', 'Rio de Janeiro', 'S\\xc3\\xa3o Gon\\xc3\\xa7alo', 'Mag\\xc3\\xa9', 'Duque de Caxias', 'Niter\\xc3\\xb3i', 'Itabora\\xc3\\xad'])\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Mapping2 updated with the errors in the city found on the Guanabara Bay map. \"\"\"\n",
    "\n",
    "mapping2 = {'Camboinha': 'Niterói',\n",
    "            'Camboinhas': 'Niterói',\n",
    "            'Caramujo': 'Niterói',\n",
    "            'Várzea das Moças, São Gonçalo': 'São Gonçalo',\n",
    "            'rio de Janeiro': 'Rio de Janeiro',\n",
    "            'SãoGonçalo': 'São Gonçalo',\n",
    "            'Maracanã': 'Rio de Janeiro',\n",
    "            'Rio de janeiro': 'Rio de Janeiro',\n",
    "            'Leblon': 'Rio de Janeiro',\n",
    "            'niterói': 'Niterói',\n",
    "            'Colubandê': 'São Gonçalo',\n",
    "            'Fonseca': 'Niterói',\n",
    "            'Niteroi': 'Niterói',\n",
    "            'rio de janeiro': 'Rio de Janeiro',\n",
    "            'Alcântara': 'São Gonçalo',\n",
    "            'niteroi': 'Niterói',\n",
    "            'Cafubá': 'Niterói',\n",
    "            'RIo de Janeiro': 'Rio de Janeiro',\n",
    "            'Rua Monsenhor Magaldi': 'Rio de Janeiro',\n",
    "            'Rio de Janeiro,': 'Rio de Janeiro',\n",
    "            'Méier': 'Rio de Janeiro',\n",
    "            'São Lourenço': 'Niterói',\n",
    "           }\n",
    "\n",
    "def update_city(city, mapping2):\n",
    "    \"\"\" For a given city return the correct city name using \"mapping2\". \"\"\"\n",
    "    try:\n",
    "        city = city.encode('utf8')\n",
    "    except:\n",
    "        pass\n",
    "    if city in mapping2:\n",
    "        city = mapping2[city.decode('utf8').encode('utf8')]\n",
    "    return city\n",
    "    \n",
    "\n",
    "\n",
    "osm_file = open(filename, \"r\")\n",
    "cities = []\n",
    "for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "    for tag in elem.iter(\"tag\"):\n",
    "        if tag.attrib['k'] == \"addr:city\":\n",
    "            tag.attrib['v'] = update_city(tag.attrib['v'], mapping2)\n",
    "            cities.append(tag.attrib['v'])\n",
    "osm_file.close()\n",
    "print set(cities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12 Quiz: Preparando-se para o Banco de Dados\n",
    "\n",
    "*Your task is to wrangle the data and transform the shape of the data*\n",
    "*into the model we mentioned earlier. The output should be a list of dictionaries*\n",
    "*that look like this:*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*{\n",
    "\"id\": \"2406124091\",\n",
    "\"type: \"node\",\n",
    "\"visible\":\"true\",\n",
    "\"created\": {\n",
    "          \"version\":\"2\",\n",
    "          \"changeset\":\"17206049\",\n",
    "          \"timestamp\":\"2013-08-03T16:43:42Z\",\n",
    "          \"user\":\"linuxUser16\",\n",
    "          \"uid\":\"1219059\"\n",
    "        },\n",
    "\"pos\": [41.9757030, -87.6921867],\n",
    "\"address\": {\n",
    "          \"housenumber\": \"5157\",\n",
    "          \"postcode\": \"60625\",\n",
    "          \"street\": \"North Lincoln Ave\"\n",
    "        },\n",
    "\"amenity\": \"restaurant\",\n",
    "\"cuisine\": \"mexican\",\n",
    "\"name\": \"La Cabana De Don Luis\",\n",
    "\"phone\": \"1 (773)-271-5176\"\n",
    "}*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*You have to complete the function 'shape_element'.*\n",
    "*We have provided a function that will parse the map file, and call the function with the element\n",
    "as an argument. You should return a dictionary, containing the shaped data for that element.\n",
    "We have also provided a way to save the data in a file, so that you could use\n",
    "mongoimport later on to import the shaped data into MongoDB.*\n",
    "\n",
    "*Note that in this exercise we do not use the 'update street name' procedures\n",
    "you worked on in the previous exercise. If you are using this code in your final\n",
    "project, you are strongly encouraged to use the code from previous exercise to \n",
    "update the street names before you save them to JSON.* \n",
    "\n",
    "*In particular the following things should be done:*\n",
    "- *you should process only 2 types of top level tags: \"node\" and \"way\"*\n",
    "- *all attributes of \"node\" and \"way\" should be turned into regular key/value pairs, except:*\n",
    "    - *attributes in the CREATED array should be added under a key \"created\"*\n",
    "    - *attributes for latitude and longitude should be added to a \"pos\" array,\n",
    "      for use in geospacial indexing. Make sure the values inside \"pos\" array are floats\n",
    "      and not strings.*\n",
    "- *if the second level tag \"k\" value contains problematic characters, it should be ignored*\n",
    "- *if the second level tag \"k\" value starts with \"addr:\", it should be added to a dictionary \"address\"*\n",
    "- *if the second level tag \"k\" value does not start with \"addr:\", but contains \":\", you can\n",
    "  process it in a way that you feel is best. For example, you might split it into a two-level\n",
    "  dictionary like with \"addr:\", or otherwise convert the \":\" to create a valid key.*\n",
    "- *if there is a second \":\" that separates the type/direction of a street,\n",
    "  the tag should be ignored, for example:*\n",
    "\n",
    "<tag k=\"addr:housenumber\" v=\"5158\"/>\n",
    "<tag k=\"addr:street\" v=\"North Lincoln Avenue\"/>\n",
    "<tag k=\"addr:street:name\" v=\"Lincoln\"/>\n",
    "<tag k=\"addr:street:prefix\" v=\"North\"/>\n",
    "<tag k=\"addr:street:type\" v=\"Avenue\"/>\n",
    "<tag k=\"amenity\" v=\"pharmacy\"/>\n",
    "\n",
    "  *should be turned into:*\n",
    "\n",
    "*{...\n",
    "\"address\": {\n",
    "    \"housenumber\": 5158,\n",
    "    \"street\": \"North Lincoln Avenue\"\n",
    "}\n",
    "\"amenity\": \"pharmacy\",\n",
    "...\n",
    "}*\n",
    "\n",
    "- *for \"way\" specifically:*\n",
    "\n",
    "  <nd ref=\"305896090\"/>\n",
    "  <nd ref=\"1719825889\"/>\n",
    "\n",
    "*should be turned into*\n",
    "\"node_refs\": [\"305896090\", \"1719825889\"]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lower = re.compile(r'^([a-z]|_)*$')\n",
    "lower_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*$')\n",
    "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "CREATED = [ \"version\", \"changeset\", \"timestamp\", \"user\", \"uid\"]\n",
    "\n",
    "\n",
    "def shape_element(element):\n",
    "    \"\"\" For a given element, returns a dictionary with the requested shape. \"\"\"\n",
    "    node = {}\n",
    "    if element.tag == \"node\" or element.tag == \"way\" :\n",
    "        node['id'] = element.attrib['id']\n",
    "        if element.tag == \"node\":\n",
    "            node['type'] = 'node'\n",
    "        if element.tag == \"way\":\n",
    "            node['type'] = 'way'\n",
    "            node['node_refs'] = []\n",
    "        try:\n",
    "            node[\"visible\"] = element.attrib[\"visible\"]\n",
    "        except:\n",
    "            pass\n",
    "        node[\"created\"] = {}\n",
    "        node[\"created\"]['version'] = element.attrib['version']\n",
    "        node[\"created\"]['changeset'] = element.attrib['changeset']\n",
    "        node[\"created\"]['timestamp'] = element.attrib['timestamp']\n",
    "        node[\"created\"]['user'] = element.attrib['user']\n",
    "        node[\"created\"]['uid'] = element.attrib['uid']\n",
    "        if element.tag == \"node\":\n",
    "            node[\"pos\"] = [float(element.attrib['lat']),float(element.attrib['lon'])]\n",
    "        node[\"address\"] = {}\n",
    "        for tag in element.iter('tag'):\n",
    "            if problemchars.search(tag.attrib['k']) == None:\n",
    "                if tag.attrib['k'] == \"addr:housenumber\":\n",
    "                    node[\"address\"][\"housenumber\"] = tag.attrib['v']\n",
    "                if tag.attrib['k'] == \"addr:postcode\":\n",
    "                    node[\"address\"][\"postcode\"] = tag.attrib['v']\n",
    "                if tag.attrib['k'] == \"addr:street\":\n",
    "                    node[\"address\"][\"street\"] = update_name(tag.attrib['v'], mapping)\n",
    "                if tag.attrib['k'] == \"addr:city\":\n",
    "                    node[\"address\"][\"city\"] = update_city(tag.attrib['v'], mapping2)\n",
    "                if tag.attrib['k'] == \"addr:amenity\":\n",
    "                    node[\"amenity\"] = tag.attrib['v']\n",
    "                if tag.attrib['k'] == \"addr:cuisine\":\n",
    "                    node[\"cuisine\"] = tag.attrib['v']\n",
    "                if tag.attrib['k'] == \"addr:name\":\n",
    "                    node[\"name\"] = tag.attrib['v']\n",
    "                if tag.attrib['k'] == \"addr:phone\":\n",
    "                    node[\"phone\"] = tag.attrib['v']\n",
    "        if node[\"address\"] == {}:\n",
    "            node.pop('address',None)\n",
    "        for tag in element.iter('nd'):        \n",
    "            node['node_refs'].append(tag.attrib['ref'])\n",
    "        return node\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def process_map(file_in, pretty = False):\n",
    "    \"\"\" For a given file, saves a JSON file with the requested shape and returns a newly shaped data. \"\"\"\n",
    "    file_out = \"{0}.json\".format(file_in)\n",
    "    data = []\n",
    "    with codecs.open(file_out, \"w\") as fo:\n",
    "        for _, element in ET.iterparse(file_in):\n",
    "            el = shape_element(element)\n",
    "            if el:\n",
    "                data.append(el)\n",
    "                if pretty:\n",
    "                    fo.write(json.dumps(el, indent=2)+\"\\n\")\n",
    "                else:\n",
    "                    fo.write(json.dumps(el) + \"\\n\")\n",
    "    return data\n",
    "\n",
    "    # NOTE: if you are running this code on your computer, with a larger dataset, \n",
    "    # call the process_map procedure with pretty=False. The pretty=True option adds \n",
    "    # additional spaces to the output, making it significantly larger.\n",
    "data = process_map(filename, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregando os dados no Banco de Dados e realizando consultas\n",
    "\n",
    "Nesse momento iremos conectar com o banco de dados MongoDB e importaremos o arquivo JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertManyResult at 0xcb36ad38>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = MongoClient('mongodb://localhost:27017')\n",
    "db = client.project\n",
    "db.OSM.insert_many(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de agora serão realizadas algumas consultas:\n",
    "\n",
    "Número de documentos e tamanho da base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count:  1679334\n",
      "size:  394502289\n"
     ]
    }
   ],
   "source": [
    "collstats = db.command(\"collstats\",'OSM')\n",
    "print 'count: ', collstats['count']\n",
    "print 'size: ', collstats['size']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Número de vias (\"way\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205436\n"
     ]
    }
   ],
   "source": [
    "query = {'type': 'way'}\n",
    "print db.OSM.find(query).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Número de nós (\"node\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1473898\n"
     ]
    }
   ],
   "source": [
    "query = {'type': 'node'}\n",
    "print db.OSM.find(query).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Número de nós em algumas ruas famosas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def street_nodes(street_name):\n",
    "    query = {'address.street': street_name, 'type': 'node'}\n",
    "    return db.OSM.find(query).count()\n",
    "street_nodes(\"Avenida Presidente Vargas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "street_nodes(\"Avenida Brasil\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "street_nodes('Calçadão de Copacabana')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "street_nodes('Avenida Atlântica')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "street_nodes('Avenida Rio Branco')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Número de usuários distintos que criaram vias (\"way\") ou nós (\"node\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1099\n"
     ]
    }
   ],
   "source": [
    "print len(db.OSM.distinct('created.uid'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
